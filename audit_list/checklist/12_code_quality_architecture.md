# Code Quality, Architecture & AI Hallucination Audit

**Priority:** P2
**Merged From:** #17 (Code Quality & Architecture), #28 (Ghost Logic & AI Hallucination)
**Status:** Active
**Last Updated:** 2025-12-26

---

## Purpose

This audit identifies structural issues, architectural violations, tech debt, and AI-generated code hallucinations that compound maintainability risks. Critical for "vibe coded" projects where AI assistance may have introduced non-existent APIs, deprecated patterns, or phantom features.

---

## Quick Reference

### Risk Markers
- âš ï¸ **AI-CODING RISK** - Hallucinated APIs, phantom features, version confusion
- ðŸ **PYTHON/FASTAPI** - Backend architecture, Pydantic patterns, async issues
- âš›ï¸ **REACT/TS** - Frontend architecture, component patterns, type safety

### Severity Levels
- **CRITICAL** - Runtime crashes, non-existent APIs, blocking issues
- **HIGH** - Deprecated APIs, significant maintainability risks, security issues
- **MEDIUM** - Code smells, tech debt, maintenance burden
- **LOW** - Style issues, minor inconsistencies

---

## AI-Generated Code Verification (CRITICAL)

âš ï¸ **AI-CODING RISK** - Verify all library usage against actual installed versions

### Quick Verification Commands

```bash
# Python library versions
pip show docling fastapi pydantic pillow opencv-python label-studio-sdk

# Node.js library versions
npm ls react react-router-dom zustand

# Verify Docling API
python -c "from docling.document_converter import DocumentConverter; print(dir(DocumentConverter))"

# Verify Pydantic version
python -c "import pydantic; print(pydantic.VERSION)"
```

### Static Analysis Tools

ðŸ **Python:**
```bash
vulture .                  # Find dead code
pylint backend/            # Unused imports/variables
mypy --strict backend/     # Type checking
radon cc backend/ -a       # Cyclomatic complexity
```

âš›ï¸ **TypeScript:**
```bash
npx ts-prune               # Find dead exports
npx eslint frontend/src/   # Linting + unused imports
npx madge --circular frontend/src/  # Circular dependencies
```

### Hallucination Hotspots Checklist

âš ï¸ **Critical Verification Items:**

- [ ] **Docling API** - All pipeline methods exist in installed version
- [ ] **Pydantic v2** - No v1 syntax (`@validator`, `.dict()`, `Config` class)
- [ ] **FastAPI** - Dependency injection, middleware, WebSocket patterns valid
- [ ] **React 19** - No hallucinated hooks (`useAsyncState`, `useServerData`)
- [ ] **Zustand** - Store patterns match v4/v5 API
- [ ] **Label Studio SDK** - All SDK methods exist in installed version
- [ ] **Environment Variables** - All referenced vars defined in `.env.example`
- [ ] **Imports** - All imports resolve to actual modules in dependencies

---

## 1) Import & API Hallucinations

âš ï¸ **AI-CODING RISK** - Non-existent methods confidently generated by AI

### A) Non-Existent Library Methods

**What to Look For:**
- Method calls that don't exist in the installed library version
- Hotspots: Docling pipeline methods, FastAPI patterns, Pydantic v2 validators

**Verification:**
```python
# REPL test for any suspicious API call
import library_name
print(dir(library_name.ClassName))
# Cross-reference with official docs for exact version
```

**Action Items:**
- [ ] Verify all `DocumentConverter` method calls against Docling docs
- [ ] Check `ConversionResult` attribute access patterns
- [ ] Validate all Pydantic model validator decorators
- [ ] Confirm FastAPI dependency injection signatures
- [ ] Test WebSocket lifecycle method calls

### B) Pydantic v1/v2 Confusion

ðŸ **PYTHON/FASTAPI** - Common AI hallucination mixing v1 and v2 syntax

**Pydantic v2 Migration Checklist:**

**Validators:**
- [ ] Replace `@validator` â†’ `@field_validator`
- [ ] Replace `@root_validator` â†’ `@model_validator`

**Configuration:**
- [ ] Replace `Config` class â†’ `model_config` dict
- [ ] Update field aliases from `Config.fields` â†’ `Field(alias=...)`

**Serialization:**
- [ ] Replace `.dict()` â†’ `.model_dump()`
- [ ] Replace `.json()` â†’ `.model_dump_json()`
- [ ] Replace `parse_obj()` â†’ `model_validate()`
- [ ] Replace `schema()` â†’ `model_json_schema()`

**Field Types:**
- [ ] Use union syntax: `str | None = None` (not `Optional[str] = None`)
- [ ] Verify `Field(...)` parameter names match v2

**Search Commands:**
```bash
# Find v1 patterns
grep -r "@validator" backend/
grep -r "\.dict()" backend/
grep -r "parse_obj" backend/
grep -r "class Config:" backend/
grep -r "Optional\[" backend/
```

### C) Deprecated API Usage

âš ï¸ **AI-CODING RISK** - APIs that work now but will break

**Action Items:**
- [ ] Scan for React class components or legacy lifecycle methods
- [ ] Check for deprecated FastAPI parameters
- [ ] Verify no outdated Label Studio SDK patterns
- [ ] Look for deprecated OpenCV/Pillow methods

### D) Phantom Import Statements

**Quick Detection:**
```bash
# Python unused imports
pylint --disable=all --enable=unused-import backend/

# TypeScript unused imports
npx eslint --rule "unused-imports/no-unused-imports: error" frontend/src/
```

**Action Items:**
- [ ] Remove all unused imports
- [ ] Verify all imports resolve to existing modules
- [ ] Check for imports from non-existent local modules

---

## 2) Docling-Specific Hallucinations

âš ï¸ **AI-CODING RISK** + ðŸ **PYTHON/FASTAPI**

### A) Non-Existent Docling Pipeline Methods

**Common Hallucinations:**
- `doc.get_elements()` - verify actual element access pattern
- Pipeline stage names that don't exist
- Conversion options not supported
- Model configuration parameters fabricated

**Verification Strategy:**
```python
# Import and inspect actual Docling objects
from docling.document_converter import DocumentConverter
from docling.datamodel.base_models import ConversionResult

converter = DocumentConverter()
print("Converter methods:", [m for m in dir(converter) if not m.startswith('_')])

# Test with sample document
result = converter.convert("sample.pdf")
print("Result type:", type(result))
print("Result attributes:", [a for a in dir(result) if not a.startswith('_')])
```

**Action Items:**
- [ ] Audit all `DocumentConverter` instantiation and configuration
- [ ] Verify all pipeline stage access patterns
- [ ] Check element iteration and filtering methods
- [ ] Validate conversion result attribute access
- [ ] Confirm model loading and configuration options

### B) Incorrect Docling Data Structures

**Common Issues:**
- `.text` vs `.content` attribute confusion
- Bounding box format: `(x,y,w,h)` vs `(x1,y1,x2,y2)`
- Page/element hierarchy assumptions
- Coordinate system confusion (PDF vs pixel vs normalized)

**Action Items:**
- [ ] Print actual Docling output for sample document
- [ ] Document actual bbox format used by Docling
- [ ] Verify page access patterns
- [ ] Check element hierarchy traversal
- [ ] Confirm coordinate system at each stage

### C) Fabricated Configuration Options

**Action Items:**
- [ ] Review all `DocumentConverter` constructor arguments
- [ ] Verify pipeline configuration options
- [ ] Check model loading parameters
- [ ] Validate feature flags and boolean options
- [ ] Cross-reference with Docling source code if docs unclear

---

## 3) Dead Code & Unrequested Features

âš ï¸ **AI-CODING RISK** - Speculative code AI added without request

### A) Orphaned Functions & Components

**Detection:**
```bash
# Python dead code
vulture backend/ --min-confidence 80

# TypeScript dead exports
npx ts-prune

# Find unused React components
grep -r "export.*function\|export.*const.*=" frontend/src/components/ | \
  while read line; do
    name=$(echo $line | grep -o "function [A-Z][a-zA-Z]*\|const [A-Z][a-zA-Z]*")
    component=$(echo $name | awk '{print $2}')
    count=$(grep -r "$component" frontend/src/ | wc -l)
    if [ $count -lt 2 ]; then echo "Possibly unused: $component in $line"; fi
  done
```

**Action Items:**
- [ ] Identify all defined-but-never-called functions
- [ ] Find React components never imported/rendered
- [ ] Locate API endpoints with no client usage
- [ ] Check for event handlers attached to nothing
- [ ] Document or remove each orphaned piece

### B) Incomplete Feature Implementations

**What to Look For:**
- Feature flags for non-existent features
- Half-implemented workflows (upload without processing)
- Substantial TODO blocks with code

**Action Items:**
- [ ] Search for `TODO:` and `FIXME:` comments
- [ ] Find feature flags with single branch used
- [ ] Identify conditional logic for phantom features
- [ ] Complete, remove, or document each incomplete feature

**Search Commands:**
```bash
grep -r "TODO:" backend/ frontend/src/
grep -r "FIXME:" backend/ frontend/src/
grep -r "HACK:" backend/ frontend/src/
```

### C) Speculative Abstractions

âš ï¸ **AI-CODING RISK** - Over-engineering for non-existent requirements

**What to Look For:**
- Factory patterns for single implementation
- Strategy patterns with one strategy
- Plugin systems with no plugins
- Configuration options never used

**Action Items:**
- [ ] Identify overly generic abstractions
- [ ] Find unused configuration parameters
- [ ] Locate single-implementation design patterns
- [ ] Simplify to actual requirements

### D) Copy-Paste Artifacts

**Action Items:**
- [ ] Find duplicate code blocks with slight variations
- [ ] Locate error messages referencing wrong features
- [ ] Check variable names that don't match purpose
- [ ] Consolidate duplicates into shared utilities

**Detection:**
```bash
# Find duplicate Python code
pylint --disable=all --enable=duplicate-code backend/

# Simple line-based duplication check
find backend/ -name "*.py" -exec sh -c 'sort "$1" | uniq -d | head -20' _ {} \;
```

---

## 4) Module Boundaries & Separation of Concerns

ðŸ **PYTHON/FASTAPI** + âš›ï¸ **REACT/TS**

### A) Leaky Abstractions

**What to Look For:**
- Business logic in API route handlers
- Database queries directly in route handlers
- Frontend components containing business logic
- Pipeline stage logic mixed with FastAPI endpoints
- Docling internals exposed to API layer

**Action Items:**
- [ ] Extract business logic from route handlers to service layer
- [ ] Move database queries to repository layer
- [ ] Extract component logic to custom hooks
- [ ] Separate stage processing from HTTP handling
- [ ] Create adapter layer for Docling integration

### B) Circular Dependencies

**Detection:**
```bash
# Python circular imports
python -c "import sys; sys.path.insert(0, 'backend'); import backend" 2>&1 | grep -i "circular\|cannot import"

# TypeScript circular dependencies
npx madge --circular frontend/src/
```

**Action Items:**
- [ ] Map import graph for both backend and frontend
- [ ] Identify circular dependency chains
- [ ] Break cycles using dependency inversion
- [ ] Extract shared types to separate module

### C) God Modules / Files

**Detection:**
```bash
# Files exceeding 500 lines
find backend/ -name "*.py" -exec wc -l {} \; | awk '$1 > 500 {print $0}' | sort -rn
find frontend/src/ -name "*.ts*" -exec wc -l {} \; | awk '$1 > 500 {print $0}' | sort -rn
```

**Action Items:**
- [ ] List all files >500 lines
- [ ] Identify multiple responsibilities per file
- [ ] Break into focused, single-purpose modules
- [ ] Follow module size limit (500 lines max)

### D) Missing Domain Boundaries

**What to Look For:**
- No separation between document processing, API, storage
- Shared mutable state across boundaries
- Docling types leaking into API responses
- Label Studio types mixed with internal models

**Action Items:**
- [ ] Define clear domain boundaries (processing, storage, API)
- [ ] Create boundary-crossing data transfer objects (DTOs)
- [ ] Map type conversion points
- [ ] Eliminate shared mutable state

---

## 5) Layering & Dependency Direction

ðŸ **PYTHON/FASTAPI**

### A) Inverted Dependencies

**What to Look For:**
- Utility modules importing from API layer
- Domain logic depending on infrastructure
- Pydantic models importing from FastAPI
- Checkpoint utilities importing from WebSocket handlers

**Action Items:**
- [ ] Map dependency graph with direction
- [ ] Identify inverted dependencies
- [ ] Apply dependency inversion principle
- [ ] Move to clean architecture layers

**Expected Layer Order (dependency direction â†’):**
```
Infrastructure â†’ Domain â†’ Application â†’ API
(database, files) â†’ (models, logic) â†’ (services, use cases) â†’ (routes, handlers)
```

### B) Missing Abstraction Layers

**What to Look For:**
- Direct SQLite calls scattered throughout codebase
- Label Studio SDK calls without adapter
- No repository pattern for data access
- External service calls without interface

**Action Items:**
- [ ] Create repository layer for all database access
- [ ] Build adapter for Label Studio integration
- [ ] Abstract file system operations
- [ ] Define interfaces for external dependencies

### C) Improper Coupling

**What to Look For:**
- Hard-coded dependencies instead of dependency injection
- Stage processors directly instantiating Docling models
- Frontend directly constructing API request shapes

**Action Items:**
- [ ] Implement dependency injection in FastAPI
- [ ] Use factory pattern for Docling model creation
- [ ] Generate TypeScript types from Pydantic models

### D) Shared Mutable State

âš ï¸ **AI-CODING RISK** - AI often generates global state patterns

**What to Look For:**
- Global variables with mutable state
- Module-level state persisting between requests
- Global document cache
- Shared WebSocket connection manager state

**Action Items:**
- [ ] Identify all module-level mutable variables
- [ ] Convert to dependency-injected singletons
- [ ] Use request-scoped state where appropriate
- [ ] Document any intentional shared state

---

## 6) Error Handling Patterns

ðŸ **PYTHON/FASTAPI** + âš›ï¸ **REACT/TS**

### A) Inconsistent Error Handling

**What to Look For:**
- Mixed exception types (custom vs built-in vs third-party)
- Inconsistent API error response shapes
- Silent failures (catching and ignoring exceptions)
- Docling exceptions not translated to API errors
- Checkpoint validation failures not surfaced

**Action Items:**
- [ ] Define standard exception hierarchy
- [ ] Create consistent API error response schema
- [ ] Implement error translation at boundaries
- [ ] Remove bare `except:` blocks
- [ ] Log all suppressed exceptions

**Search for Anti-patterns:**
```bash
grep -r "except:" backend/           # Bare except
grep -r "except Exception:" backend/ # Overly broad
grep -r "pass" backend/ | grep -B2 "except"  # Silent failures
```

### B) Missing Error Boundaries

**What to Look For:**
- No centralized error handling middleware
- React components without error boundaries
- Unhandled promise rejections
- Pipeline stage failures not propagated
- WebSocket errors not handled

**Action Items:**
- [ ] Add FastAPI exception handler middleware
- [ ] Wrap React app in error boundary
- [ ] Add global `unhandledrejection` handler
- [ ] Create stage error propagation mechanism
- [ ] Handle WebSocket errors in Zustand store

### C) Improper Exception Usage

**What to Look For:**
- Exceptions used for control flow
- Not re-raising with context
- Catching all Docling exceptions without distinguishing

**Action Items:**
- [ ] Replace control-flow exceptions with return values
- [ ] Add context when re-raising exceptions
- [ ] Categorize Docling exceptions (recoverable vs fatal)
- [ ] Document expected exception types per function

### D) Missing Validation

âš ï¸ **AI-CODING RISK** - AI may skip input validation

**What to Look For:**
- Input validation gaps at API boundaries
- Missing schema validation for checkpoint files
- Frontend not validating API responses
- Pydantic models missing custom validators

**Action Items:**
- [ ] Add Pydantic models for all API request/response
- [ ] Validate checkpoint JSON against schema
- [ ] Use Zod or similar for frontend validation
- [ ] Add custom validators for business rules

---

## 7) Type Safety & Schema Evolution

ðŸ **PYTHON/FASTAPI** + âš›ï¸ **REACT/TS**

### A) Type Drift Between Frontend/Backend

âš ï¸ **AI-CODING RISK** - AI generates types independently

**What to Look For:**
- Pydantic models not matching TypeScript interfaces
- Enum values out of sync
- Optional vs required field mismatches
- Pipeline stage status enums, checkpoint schemas

**Action Items:**
- [ ] Generate TypeScript types from Pydantic models (use `pydantic-to-typescript`)
- [ ] Sync all enum definitions
- [ ] Add type drift detection to CI
- [ ] Document schema evolution process

**Type Generation:**
```bash
# Generate TS types from Pydantic
pydantic2ts --module backend.api.models --output frontend/src/types/api.ts
```

### B) Missing Type Annotations

**Detection:**
```bash
# Python type coverage
mypy --strict backend/ 2>&1 | grep "Function is missing"
mypy --strict backend/ 2>&1 | grep "Any"

# TypeScript any usage
grep -r ": any" frontend/src/
grep -r "as any" frontend/src/
```

**Action Items:**
- [ ] Add type hints to all function signatures
- [ ] Replace `Any` with proper types
- [ ] Remove TypeScript `any` casts
- [ ] Enable `--strict` mode for both mypy and tsc

### C) Schema Evolution Risks

**What to Look For:**
- No versioning for checkpoint format
- Breaking API changes without version bump
- Missing migrations for schema changes

**Action Items:**
- [ ] Add version field to checkpoint schema
- [ ] Implement schema migration system
- [ ] Version API endpoints for breaking changes
- [ ] Document backwards compatibility policy

### D) Unsafe Type Assertions

âš ï¸ **AI-CODING RISK** - AI uses casts confidently without validation

**What to Look For:**
- TypeScript `as` casts without validation
- Python `cast()` without runtime checks
- Casting Label Studio responses
- Assuming Docling output shapes

**Action Items:**
- [ ] Replace unsafe casts with type guards
- [ ] Add runtime validation before casting
- [ ] Use Pydantic for external data parsing
- [ ] Document type assumptions

---

## 8) Frontend-Specific Quality

âš›ï¸ **REACT/TS**

### A) Component Architecture

**What to Look For:**
- Components >300 lines
- Mixed presentation and logic
- Props drilling instead of context/Zustand
- StageViewer monolith, BboxEditor complexity

**Action Items:**
- [ ] Identify components >300 lines
- [ ] Extract logic to custom hooks
- [ ] Use Zustand for cross-component state
- [ ] Split large components by responsibility

### B) State Management Issues

âš ï¸ **AI-CODING RISK** - AI may misuse Zustand patterns

**What to Look For:**
- Zustand store with too many responsibilities
- Derived state not memoized
- Stale closures in callbacks
- Mixed document/pipeline/UI state in single store

**Action Items:**
- [ ] Split store into domain slices
- [ ] Use selectors for derived state
- [ ] Add memoization with `useMemo`/`useCallback`
- [ ] Document state ownership

### C) Hook Hygiene

**What to Look For:**
- Custom hooks with uncontrolled side effects
- Missing cleanup in `useEffect`
- Dependencies array issues
- WebSocket connection hooks, document polling

**Action Items:**
- [ ] Add cleanup functions to all `useEffect`
- [ ] Fix dependency arrays (use eslint-plugin-react-hooks)
- [ ] Avoid side effects in custom hooks
- [ ] Document hook lifecycle

**Lint Check:**
```bash
npx eslint --rule "react-hooks/exhaustive-deps: error" frontend/src/
```

### D) Performance Anti-patterns

**What to Look For:**
- Inline object/function creation in render
- Missing `React.memo` on expensive components
- Unnecessary re-renders from context
- Bbox rendering, page image re-loading

**Action Items:**
- [ ] Memoize inline functions with `useCallback`
- [ ] Wrap expensive components in `React.memo`
- [ ] Split context to reduce re-renders
- [ ] Profile rendering performance

---

## 9) Backend-Specific Quality

ðŸ **PYTHON/FASTAPI**

### A) FastAPI Patterns

**What to Look For:**
- Route handlers doing too much
- Missing dependency injection
- Improper background task usage
- Stage processing in route handlers

**Action Items:**
- [ ] Extract route handler logic to services
- [ ] Use FastAPI `Depends()` for dependencies
- [ ] Review background task usage
- [ ] Add lifespan event handlers

### B) Pydantic Usage

âš ï¸ **AI-CODING RISK** - See Section 1B for v1/v2 confusion

**What to Look For:**
- Validation logic in wrong layer
- Duplicate schema definitions
- Improper `model_config` usage
- Checkpoint models, API models, stage data models

**Action Items:**
- [ ] Consolidate duplicate Pydantic models
- [ ] Move validation to model layer
- [ ] Use model inheritance for shared schemas
- [ ] Review all `model_config` settings

### C) Async Patterns

âš ï¸ **AI-CODING RISK** - AI may mix sync/async incorrectly

**What to Look For:**
- Blocking calls in async functions
- Missing `await` on coroutines
- Improper async context manager usage
- Synchronous Docling calls blocking event loop
- File I/O without `run_in_executor`

**Action Items:**
- [ ] Audit all async functions for blocking calls
- [ ] Use `asyncio.to_thread()` for sync operations
- [ ] Add `await` to all coroutine calls
- [ ] Profile async performance

**Detection:**
```bash
# Find async functions with potentially blocking calls
grep -A20 "async def" backend/ | grep -E "open\(|read\(|write\(" | grep -v "await"
```

### D) Resource Management

**What to Look For:**
- Missing context managers
- Database connections not properly closed
- File handles leaking
- Checkpoint file handling, SQLite lifecycle

**Action Items:**
- [ ] Use `with` statements for all resources
- [ ] Add connection pooling if needed
- [ ] Implement proper cleanup in `finally` blocks
- [ ] Audit temporary file deletion

---

## 10) Pipeline-Specific Architecture

ðŸ **PYTHON/FASTAPI** - Core domain logic

### A) Stage Isolation

**What to Look For:**
- Stages with hidden dependencies
- Shared state between stages
- Stages modifying input data
- Stage N assuming Stage N-1 output shape

**Action Items:**
- [ ] Document stage input/output contracts
- [ ] Make stage dependencies explicit
- [ ] Use immutable data structures
- [ ] Add stage interface validation

### B) Checkpoint Integrity

âš ï¸ **AI-CODING RISK** - Critical for system correctness

**What to Look For:**
- Checkpoint format not self-describing
- Missing checksums or validation
- No atomic write guarantees
- Partial checkpoint writes, no schema version

**Action Items:**
- [ ] Add schema version to checkpoint format
- [ ] Implement atomic write (write-then-rename)
- [ ] Add checksum validation
- [ ] Create checkpoint validation schema

### C) Coordinate System Consistency

**What to Look For:**
- Mixed coordinate systems (PDF vs pixel vs normalized)
- Transformation logic duplicated
- Missing origin documentation
- Docling vs display vs Label Studio coordinates

**Action Items:**
- [ ] Document coordinate system at each stage
- [ ] Create centralized transformation utilities
- [ ] Add coordinate system to bbox data model
- [ ] Validate coordinate ranges

### D) Export Format Coupling

**What to Look For:**
- Export logic knowing internal structure
- Format-specific code scattered
- Missing format abstraction
- Markdown/JSON export duplicating logic

**Action Items:**
- [ ] Create export adapter interface
- [ ] Implement format-specific exporters
- [ ] Centralize export logic
- [ ] Add format registry pattern

---

## 11) Integration Point Hallucinations

âš ï¸ **AI-CODING RISK** + ðŸ **PYTHON/FASTAPI**

### A) Label Studio SDK Misuse

**What to Look For:**
- Non-existent SDK methods
- Incorrect annotation format assumptions
- Authentication patterns that don't work
- Project configuration options unsupported

**Verification:**
```python
from label_studio_sdk import Client
print(dir(Client))
# Cross-reference with Label Studio SDK docs
```

**Action Items:**
- [ ] Verify all Label Studio SDK method calls
- [ ] Test annotation export/import format
- [ ] Validate authentication flow
- [ ] Check project template configuration

### B) WebSocket Protocol Hallucinations

**What to Look For:**
- Message types not handled on both ends
- Reconnection logic mismatch
- Heartbeat/ping patterns not implemented

**Action Items:**
- [ ] Document WebSocket message protocol
- [ ] Verify client/server message handlers match
- [ ] Test reconnection behavior
- [ ] Add heartbeat if needed

### C) File System Operation Hallucinations

**What to Look For:**
- Assumed paths that don't exist
- OS-specific paths without cross-platform handling
- File permission assumptions

**Action Items:**
- [ ] Use `pathlib` for all path operations
- [ ] Verify paths exist before operations
- [ ] Handle permission errors gracefully
- [ ] Test on Linux/macOS/Windows

---

## 12) Configuration & Environment

âš ï¸ **AI-CODING RISK** - AI assumes env vars exist

### A) Non-Existent Environment Variables

**What to Look For:**
- Code referencing undefined env vars
- Default values masking missing config
- Environment-specific logic for phantom environments

**Action Items:**
- [ ] Document all required env vars in `.env.example`
- [ ] Add startup validation for required vars
- [ ] Remove references to undefined vars
- [ ] Use Pydantic Settings for env config

**Validation Script:**
```python
# backend/core/config.py - add startup check
from pydantic_settings import BaseSettings

class Settings(BaseSettings):
    # Define all env vars here
    class Config:
        env_file = ".env"

    def validate_required(self):
        # Raise if any required var is missing
        pass
```

### B) Phantom Dependencies

**Detection:**
```bash
# Python imports not in requirements.txt
python -m pip list --format=freeze > installed.txt
grep -r "^import\|^from" backend/ | \
  sed 's/.*import \([a-zA-Z_][a-zA-Z0-9_]*\).*/\1/' | \
  sort -u | \
  while read pkg; do
    grep -q "^$pkg==" requirements.txt || echo "Missing: $pkg"
  done

# TypeScript imports not in package.json
npx depcheck frontend/
```

**Action Items:**
- [ ] Audit all imports against dependency files
- [ ] Remove unused dependencies
- [ ] Add missing dependencies
- [ ] Pin versions for reproducibility

### C) Build Configuration Hallucinations

**What to Look For:**
- Vite config options that don't exist
- Invalid TypeScript compiler options
- Test config for non-existent frameworks

**Action Items:**
- [ ] Validate Vite config against docs
- [ ] Check `tsconfig.json` for invalid options
- [ ] Verify test configuration
- [ ] Remove unused build configurations

---

## Architecture Health Score Rubric (1-10)

Rate overall architectural health based on findings:

- **9-10**: Clean architecture; minor improvements only
- **7-8**: Good structure with 1-2 areas needing attention
- **5-6**: Noticeable tech debt; refactoring needed before major features
- **3-4**: Significant issues; development velocity impacted
- **<3**: Fundamental restructuring required; high defect risk

**Score:** _[To be filled during audit]_

**Justification:**
- _[Key findings]_
- _[Impact on development]_
- _[Critical risks]_

**Top 3 Fixes (Highest Impact):**
1. _[Fix description]_
2. _[Fix description]_
3. _[Fix description]_

---

## Hallucination Score Rubric (Code Authenticity 1-10)

Rate code authenticity based on hallucination density:

- **9-10**: Minimal hallucinations; code matches actual APIs
- **7-8**: Few issues; mostly correct with some deprecated patterns
- **5-6**: Moderate issues; several hallucinated methods or dead code
- **3-4**: Significant issues; many non-existent APIs or phantom features
- **<3**: Severe; core functionality relies on hallucinated APIs

**Score:** _[To be filled during audit]_

**Justification:**
- _[Hallucination density]_
- _[Critical vs minor issues]_
- _[Impact on stability]_

**Top 5 Fixes (Highest Impact):**
1. _[Fix description]_
2. _[Fix description]_
3. _[Fix description]_
4. _[Fix description]_
5. _[Fix description]_

---

## Summary & Action Plan

### 1) Fix Immediately (Runtime Errors, Blocking)
- [ ] _[Non-existent API calls]_
- [ ] _[Import errors]_
- [ ] _[Critical integration hallucinations]_
- [ ] _[Architecture issues blocking development]_

**Estimated Effort:** _[Range]_

### 2) Fix Soon (Correctness, Before Next Feature)
- [ ] _[Deprecated API usage]_
- [ ] _[Incorrect data structure assumptions]_
- [ ] _[Significant maintainability issues]_
- [ ] _[Integration mismatches]_

**Estimated Effort:** _[Range]_

### 3) Fix Opportunistically (During Related Work)
- [ ] _[Dead code removal]_
- [ ] _[Code smells]_
- [ ] _[Unused imports]_
- [ ] _[Speculative abstractions]_

**Estimated Effort:** _[Range]_

### 4) Document/Accept (Known Limitations)
- [ ] _[Intentional stubs]_
- [ ] _[Version-specific workarounds]_
- [ ] _[Known limitations with clear rationale]_

---

## Metrics to Track Architecture Health

### Code Quality Metrics
```bash
# Module size distribution
find backend/ frontend/src/ -name "*.py" -o -name "*.ts*" | xargs wc -l | sort -rn | head -20

# Cyclomatic complexity
radon cc backend/ -a

# Import depth / dependency graph
pydeps backend/ --show-deps
npx madge --image frontend-deps.png frontend/src/

# Type coverage
mypy --strict --html-report mypy-report backend/
npx tsc --noEmit --strict

# Duplication percentage
pylint --disable=all --enable=duplicate-code backend/
npx jscpd frontend/src/
```

### Recommended Continuous Monitoring

**Python:**
- `ruff` - Fast linting and formatting
- `mypy --strict` - Type checking
- `radon` - Complexity analysis
- `vulture` - Dead code detection
- `bandit` - Security issues

**TypeScript:**
- `eslint` - Linting with plugins
- `tsc --strict` - Type checking
- `madge --circular` - Circular dependency detection
- `ts-prune` - Dead code detection
- `depcheck` - Unused dependencies

**Both:**
- `sonarqube` or `codeclimate` - Continuous tracking
- Pre-commit hooks for automated checks
- CI pipeline with quality gates

---

## Issue Template

For each finding, document as:

```
[SEVERITY: CRITICAL | HIGH | MEDIUM | LOW]

Location: FileName:LineNumber(s)
Risk Category: [Boundaries|Layering|Errors|Debt|Types|Frontend|Backend|Pipeline|Import|API|Dead Code|Integration|Configuration]
Markers: [âš ï¸ AI-CODING RISK] [ðŸ PYTHON/FASTAPI] [âš›ï¸ REACT/TS]

The Problem:
- [2-4 sentences explaining the issue]
- [Specific impact on maintainability/correctness/stability]

Evidence:
- [Problematic code snippet]
- [Reference to actual API/documentation]
- Confidence: High | Medium | Low

How to Verify:
- [Concrete verification step - REPL test, docs link, version check]

Technical Debt Impact:
- Effort to fix: Trivial (<1hr) | Small (1-4hr) | Medium (1-2 days) | Large (1 week+)
- Impact if unfixed: Low | Medium | High | Critical
- Confidence: High | Medium | Low

Code Smell Indicators:
- [Specific violations - line count, nesting, responsibilities]

The Fix:
- [Refactored approach or code snippet]
- [Target structure/pattern]
- [Strategy if large refactor]

Trade-off Consideration:
- [Refactor complexity, risk, breaking changes]
- [Whether acceptable short-term]

Impact if Unfixed:
- [Runtime error, silent failure, security issue, maintenance burden]
```

---

## Final Checklist

### Before Starting Audit:
- [ ] Extract library versions from `requirements.txt` and `package.json`
- [ ] Note breaking changes for major libraries (Docling, Pydantic, React)
- [ ] Set up verification environment (REPL, test project)
- [ ] Identify custom modules that may reference external libraries

### During Audit:
- [ ] Use markers consistently (âš ï¸, ðŸ, âš›ï¸)
- [ ] Verify confidence level for each finding
- [ ] Provide concrete verification steps
- [ ] Include code snippets for evidence
- [ ] Estimate effort and impact

### After Audit:
- [ ] Calculate architecture health score
- [ ] Calculate hallucination score
- [ ] Prioritize top fixes
- [ ] Create actionable summary
- [ ] Document metrics and tooling recommendations
